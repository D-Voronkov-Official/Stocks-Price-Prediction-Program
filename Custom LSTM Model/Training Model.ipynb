{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244e1fe-230b-4b00-89ee-cf50a42ea436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from model import StocksPredictionModel\n",
    "from stocks_dataset import StocksDataSet\n",
    "from type_enums.ModelType import ModelType as mt\n",
    "from type_enums.SplitType import SplitType as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ee46a-0b0b-4d55-bd6a-a32736d254d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238db913-4fce-41a9-b3f5-48bd048c18e8",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c298be9-5a06-47b9-978b-780dbb15111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_with_kwargs(model, epochs, lr, split_type, standardized = True, serial_num = \"01\"):\n",
    "    \"\"\"Save the model as .pth file\n",
    "\n",
    "    Args:\n",
    "        model (StocksPredictionModel class): model, which we want to save as the file\n",
    "        epochs (integer): how many epochs was used during the training\n",
    "        lr (float): what learning rate was used during the training\n",
    "        split_type (SplitType enum): What split type was used during the training\n",
    "        standardized (bool, optional): was the data standardized with scikitlearn tools during the training\n",
    "        . Defaults to True.\n",
    "        serial_num (str, optional): optional string that allows to differ training \n",
    "        approaches in file name. Defaults to \"01\".\n",
    "    \"\"\"\n",
    "    torch.save([model.kwargs, model.state_dict()], \n",
    "               f\"./Models Examples/{serial_num}_{epochs}epochs_{model.model_type.value}_{lr}lr_{split_type}_std{standardized}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99119751-ca48-4bda-822c-aab8c1ccaf72",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa144993-e535-4395-baf3-8be7df15b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(ds, model, learning_rate, epochs):\n",
    "    \"\"\"Train the model based on certain criterias\n",
    "\n",
    "    Args:\n",
    "        ds (StocksDataSet): data set on which our model will be trained\n",
    "        model (StocksPredictionModel): model to train\n",
    "        learning_rate (float): learning rate for the model\n",
    "        epochs (integer): number of epochs\n",
    "    \"\"\"\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for X_train, X_test, y_train, y_test in ds:\n",
    "            if X_train is not None:\n",
    "                try:\n",
    "                    X_train = torch.Tensor(X_train).squeeze(0)\n",
    "                    model.train()\n",
    "                    model = model.to(device)\n",
    "                    X_train.to(device)\n",
    "            \n",
    "                    y_pred = model(X_train)\n",
    "                \n",
    "                \n",
    "                    optimizer.zero_grad()\n",
    "                    y_pred = y_pred.to(device)\n",
    "                    y_train = y_train.to(device)\n",
    "                    loss = loss_fn(y_pred, y_train)\n",
    "                    loss = loss.to(device)\n",
    "                \n",
    "                    loss.backward()\n",
    "                \n",
    "                    optimizer.step()\n",
    "                \n",
    "                    model.eval()\n",
    "                    \n",
    "                \n",
    "                    with torch.inference_mode():\n",
    "                    \n",
    "                        test_pred = model(X_test)\n",
    "                        test_pred.to(device)\n",
    "                        y_test = y_test.to(device)\n",
    "                        test_loss = loss_fn(test_pred, y_test)\n",
    "                        if epoch == epochs - 1 or epoch % 100 == 0:\n",
    "                            print(f\"Epoch number: {epoch}\")\n",
    "                            print(f\"Test Loss is: {test_loss}\")\n",
    "                            print(f\"Train Loss is: {loss}\")\n",
    "                except ValueError:\n",
    "                    print(\"File skipped because it's too short!\")\n",
    "            print(f\"{epoch} epoch finished\")\n",
    "            \n",
    "    save_with_kwargs(model, epochs, learning_rate, ds.prep_type.value, ds.standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f194eaf-aa42-4d03-99b4-64e07ff37402",
   "metadata": {},
   "source": [
    "# Training process testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f787f3-03ad-4ddb-bd86-abee01c50cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model = train_model(StocksDataSet(\"../Custom LSTM Model/Data/Stocks Data\", \n",
    "                                      preparation_type=st.CustomSplit), \n",
    "                        StocksPredictionModel(input_size=16,\n",
    "                                              num_classes = 30, \n",
    "                                              hidden_size=256, \n",
    "                                              num_layers=1, \n",
    "                                              modelType = mt.ComplexModel), \n",
    "                        learning_rate= 0.001, \n",
    "                        epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f1ecf2-b694-4490-98e4-0dfd6d0e4b59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
